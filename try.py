# -*- coding: utf-8 -*-
"""try.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11RHxFObu3MHq8diRZnlf6pCb_DjjPTSL
"""

import streamlit as st
from PIL import Image, ImageDraw, ImageFont
import tempfile, os, io, sys
import numpy as np

# --- UI style (kept from your original) ---
blue_overlay = """
<style>
.stApp {
  background: linear-gradient(120deg, #89f7fe, #66a6ff);
  min-height: 100vh;
}
.stApp .main {
  background-color: rgba(255, 255, 255, 0.65);
  backdrop-filter: blur(8px);
  margin: 2rem;
  padding: 2rem;
  border-radius: 20px;
  box-shadow: 0 4px 25px rgba(0,0,0,0.15);
}
</style>
"""
st.set_page_config(page_title="Automated Ear Disease Detection (Enhanced)", layout="wide")
st.markdown(blue_overlay, unsafe_allow_html=True)
st.title("Automated Ear Disease Detection — YOLOv12 (enhanced inference)")

# --- Left: Inputs ---
col1, col2 = st.columns([1, 2])
with col1:
    st.header("Inputs")
    uploaded_image = st.file_uploader("Upload an otoscopic image", type=["png", "jpg", "jpeg"])
    model_file = st.file_uploader("Upload a model (.pt or .onnx) — optional", type=["pt", "onnx", "yaml"])
    conf = st.slider("Confidence threshold", 0.0, 1.0, 0.25, 0.01)
    iou = st.slider("NMS IoU threshold", 0.0, 1.0, 0.45, 0.01)
    imgsz = st.slider("Inference image size (px)", 256, 1536, 640, step=32)
    save_annotated = st.checkbox("Save annotated result to disk", value=False)
    run = st.button("Run inference")

# --- Right: Preview / Results ---
with col2:
    st.header("Preview / Result")
    if uploaded_image is None:
        st.info("Upload an otoscopic image to begin analysis.")
    else:
        input_img = Image.open(uploaded_image).convert("RGB")
        st.image(input_img, caption="Input image", use_column_width=True)
        if not run:
            st.caption("Click **Run inference** to detect possible ear conditions.")

# --- Helper functions ---
def detect_device():
    try:
        import torch
        if torch.cuda.is_available():
            return "cuda"
    except Exception:
        pass
    return "cpu"

def load_ultralytics_model(path, device="cpu", prefer_onnx=False):
    """
    Load YOLO model using ultralytics.YOLO. Supports .pt and .onnx (if ultralytics supports ONNX runtime).
    Returns model object or None.
    """
    try:
        from ultralytics import YOLO
    except Exception as e:
        st.error(f"ultralytics package is required but not installed or failed to import: {e}")
        return None

    try:
        # Use device selection and half precision if on CUDA
        model = YOLO(path)
        # set model attributes to improve inference behaviour (if supported)
        try:
            model.to(device)
            if device.startswith("cuda"):
                # attempt to set half precision for fp16 inference (if supported)
                model.model.half()  # best-effort; ignore if attribute missing
        except Exception:
            pass
        return model
    except Exception as ex:
        st.warning(f"Failed to load model from {path}: {ex}")
        return None

def draw_boxes_pil(pil_img, boxes, scores, classes, class_names=None):
    """
    Draw bounding boxes with labels on a PIL.Image and return annotated PIL.Image.
    boxes: Nx4 array [x1,y1,x2,y2]
    scores: length N
    classes: length N (int indices)
    class_names: mapping index -> name (optional)
    """
    img = pil_img.copy()
    draw = ImageDraw.Draw(img)
    w, h = img.size
    try:
        font = ImageFont.truetype("DejaVuSans.ttf", size=max(12, w//50))
    except Exception:
        font = ImageFont.load_default()
    for (x1, y1, x2, y2), s, c in zip(boxes, scores, classes):
        label = (class_names.get(int(c), str(int(c))) if class_names else str(int(c))) + f" {s:.2f}"
        draw.rectangle([x1, y1, x2, y2], outline="red", width=max(2, w//200))
        text_size = draw.textsize(label, font=font)
        text_bg = [x1, y1-text_size[1]-4, x1+text_size[0]+6, y1]
        draw.rectangle(text_bg, fill="red")
        draw.text((x1+3, y1-text_size[1]-2), label, fill="white", font=font)
    return img

def fallback_draw_from_result(result, pil_img):
    """
    Best-effort draw function if model.plot() isn't available.
    """
    # try to read boxes from result
    boxes = []
    scores = []
    classes = []
    # ultralytics result access patterns
    try:
        b = getattr(result, "boxes", None)
        if b is not None:
            # b.xyxy is a tensor/array Nx4
            xy = getattr(b, "xyxy", None)
            confs = getattr(b, "conf", None)
            cls = getattr(b, "cls", None)
            if xy is not None:
                boxes = np.array(xy.cpu().numpy() if hasattr(xy, "cpu") else xy)
            if confs is not None:
                scores = np.array(confs.cpu().numpy() if hasattr(confs, "cpu") else confs).reshape(-1)
            if cls is not None:
                classes = np.array(cls.cpu().numpy() if hasattr(cls, "cpu") else cls).reshape(-1)
    except Exception:
        pass

    if len(boxes) > 0:
        return draw_boxes_pil(pil_img, boxes, scores, classes)
    # nothing to draw
    return pil_img

# --- Inference flow ---
if run:
    if uploaded_image is None:
        st.error("Please upload an image first.")
        st.stop()

    # Save input image to a temporary file
    tmp_img_file = tempfile.NamedTemporaryFile(delete=False, suffix=".jpg")
    tmp_img_file.write(uploaded_image.getbuffer())
    tmp_img_file.flush()
    tmp_img_file.close()

    # Build model path: uploaded model > local best.pt
    model_path = None
    if model_file is not None:
        # persist uploaded model to tempdir
        model_path = os.path.join(tempfile.gettempdir(), model_file.name)
        with open(model_path, "wb") as f:
            f.write(model_file.getbuffer())
    else:
        candidate = os.path.join(os.getcwd(), "best.pt")
        if os.path.exists(candidate):
            model_path = candidate

    device = detect_device()
    st.info(f"Using device: {device}")

    model = None
    if model_path:
        st.info(f"Loading model from: {os.path.basename(model_path)}")
        model = load_ultralytics_model(path=model_path, device=device)
        if model is None:
            st.warning("Model load failed — will run demo fallback inference.")
    else:
        st.info("No model provided or found locally. Running demo fallback inference.")

    # Load input PIL image
    input_pil = Image.open(tmp_img_file.name).convert("RGB")

    result_image = None
    if model is not None:
        try:
            st.info("Running inference...")
            # predictable predict call for ultralytics YOLO
            results = model.predict(source=tmp_img_file.name,
                                    imgsz=imgsz,
                                    conf=conf,
                                    iou=iou,
                                    device=device,
                                    verbose=False)
            r = results[0]

            # Preferred: use the model's plotting utility (r.plot())
            annot = None
            try:
                annot_np = r.plot()  # returns numpy array if available
                if isinstance(annot_np, np.ndarray):
                    result_image = Image.fromarray(annot_np)
                else:
                    # fallback to PIL conversion if needed
                    result_image = Image.fromarray(np.asarray(annot_np))
            except Exception:
                # fallback: extract boxes and draw manually
                result_image = fallback_draw_from_result(r, input_pil)
                st.warning("Used fallback drawing (couldn't call r.plot()).")

            # If segmentation masks exist and r.masks is present, try overlaying them
            try:
                masks = getattr(r, "masks", None)
                if masks is not None and getattr(masks, "data", None) is not None:
                    # r.plot() often includes masks; this is just an additional safety step
                    st.info("Segmentation masks found and included in visualization.")
            except Exception:
                pass

        except Exception as ex:
            st.error(f"Model inference failed: {ex}")
            # fallback to demo box
            result_image = fallback_draw_from_result(r if 'r' in locals() else None, input_pil)

    else:
        # demo fallback: draw a central box as placeholder (keeps UI working)
        w, h = input_pil.size
        demo_box = (int(w*0.15), int(h*0.15), int(w*0.85), int(h*0.85))
        draw = ImageDraw.Draw(input_pil)
        draw.rectangle(demo_box, outline="red", width=6)
        try:
            font = ImageFont.truetype("DejaVuSans.ttf", size=20)
        except Exception:
            font = ImageFont.load_default()
        draw.text((demo_box[0], demo_box[1]-24), "demo_condition:0.99", fill="red", font=font)
        result_image = input_pil

    # Show result
    if result_image is not None:
        st.image(result_image, caption="Detection / Segmentation result", use_column_width=True)
        # Save annotated image if requested
        if save_annotated:
            out_path = os.path.join(os.getcwd(), f"annotated_result_{os.path.basename(tmp_img_file.name)}")
            try:
                result_image.save(out_path)
                st.success(f"Annotated image saved to: {out_path}")
            except Exception as e:
                st.warning(f"Could not save annotated image: {e}")